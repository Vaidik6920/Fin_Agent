# === ğŸ§  FinAgentX - Autonomous Trading Agent ===
# Combined Interactive Notebook for Google Colab

# === STEP 1: Install Dependencies ===
!pip install yfinance pandas numpy torch transformers langchain faiss-cpu ray -q

# === STEP 2: Import Libraries ===
import yfinance as yf
import numpy as np
import pandas as pd
import torch
from transformers import pipeline
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.document_loaders import WebBaseLoader
import gym
from gym import spaces
from ray.rllib.agents.ppo import PPOTrainer

# === STEP 3: Market Data Retrieval ===
def get_historical_data(ticker="AAPL", period="6mo", interval="1d"):
    print("ğŸ“‰ Downloading historical data...")
    data = yf.download(ticker, period=period, interval=interval)
    return data['Close'].values

# === STEP 4: Market Sentiment Analyzer (RAG Placeholder) ===
class MarketSentimentAnalyzer:
    def __init__(self):
        print("ğŸ” Initializing sentiment pipeline...")
        self.sentiment_pipeline = pipeline("sentiment-analysis")

    def analyze_sentiment(self, text):
        result = self.sentiment_pipeline(text)[0]
        return result['label'], result['score']

# === STEP 5: Custom Trading Environment ===
class TradingEnv(gym.Env):
    def __init__(self, prices):
        self.prices = prices
        self.current_step = 0
        self.initial_balance = 10000
        self.balance = self.initial_balance
        self.holdings = 0

        self.action_space = spaces.Discrete(3)  # Buy, Sell, Hold
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(2,), dtype=np.float32)

    def reset(self):
        self.current_step = 0
        self.balance = self.initial_balance
        self.holdings = 0
        return self._get_obs()

    def _get_obs(self):
        price = self.prices[self.current_step]
        return np.array([price, self.holdings], dtype=np.float32)

    def step(self, action):
        price = self.prices[self.current_step]

        if action == 0:  # Buy
            num_shares = self.balance // price
            self.holdings += num_shares
            self.balance -= num_shares * price
        elif action == 1:  # Sell
            self.balance += self.holdings * price
            self.holdings = 0

        self.current_step += 1
        done = self.current_step >= len(self.prices) - 1

        portfolio_value = self.balance + self.holdings * price
        reward = portfolio_value - self.initial_balance

        return self._get_obs(), reward, done, {}

# === STEP 6: Train RL Agent ===
def train_rl_agent(prices):
    print("ğŸ‹ï¸ Training PPO agent...")
    trainer = PPOTrainer(env=TradingEnv, config={
        "env_config": {"prices": prices},
        "framework": "torch",
        "num_workers": 1,
    })

    for i in range(5):  # Fewer iterations for Colab
        result = trainer.train()
        print(f"âœ… Iteration {i + 1} | Avg. Reward: {result['episode_reward_mean']:.2f}")

    return trainer

# === STEP 7: Evaluate Agent (Accuracy Checker) ===
def evaluate_agent(trainer, prices):
    print("ğŸ§ª Evaluating trained agent...")
    env = TradingEnv(prices)
    obs = env.reset()
    total_reward = 0
    done = False

    while not done:
        action = trainer.compute_action(obs)
        obs, reward, done, _ = env.step(action)
        total_reward += reward

    final_value = env.balance + env.holdings * prices[env.current_step]
    print(f"ğŸ“ˆ Final Portfolio Value: ${final_value:.2f}")
    print(f"ğŸ§® Total Reward: {total_reward:.2f}")

# === STEP 8: Execute All Steps ===
print("ğŸš€ Starting FinAgentX pipeline...")

# 1. Get data
prices = get_historical_data("AAPL")

# 2. Analyze market sentiment
sentiment_analyzer = MarketSentimentAnalyzer()
news = "Apple stock is expected to outperform expectations this quarter."
label, score = sentiment_analyzer.analyze_sentiment(news)
print(f"ğŸ“° Sentiment: {label} (Confidence: {score:.2f})")

# 3. Train agent
trained_agent = train_rl_agent(prices)

# 4. Evaluate performance
evaluate_agent(trained_agent, prices)

print("âœ… FinAgentX complete.")
